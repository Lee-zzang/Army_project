import os
import json
import shutil
import yaml
from PIL import Image
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

# ==================== ì„¤ì • ====================
class_map = {
    "ì–´ì„ ": 0,
    "ìƒì„ ": 1,
    "êµ°í•¨": 2,
    "ì‚¬ëŒ": 3,
    "ìœ ì¡°ë¥˜": 4
}

# ==================== JSON â†’ YOLO ë³€í™˜ ====================
def convert_single_file(args):
    """ë‹¨ì¼ JSON íŒŒì¼ì„ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    file, json_dir, img_dir, out_dir = args
    
    result = {"status": "success", "file": file, "lines": 0}
    
    try:
        json_path = os.path.join(json_dir, file)
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        anns = data.get("annotations", [])
        if not anns:
            result["status"] = "skipped"
            result["reason"] = "no_annotations"
            return result

        yolo_lines = []
        for ann in anns:
            # í´ë˜ìŠ¤ ID ê²€ì¦
            try:
                cls_id = int(ann["class"]) - 1  # 1~5 â†’ 0~4
            except (KeyError, ValueError):
                result["status"] = "error"
                result["reason"] = f"invalid_class: {ann.get('class', 'N/A')}"
                return result
            
            if not 0 <= cls_id <= 4:
                result["status"] = "error"
                result["reason"] = f"class_out_of_range: {cls_id}"
                return result

            # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            img_path = os.path.join(img_dir, ann["filename"])
            if not os.path.exists(img_path):
                result["status"] = "skipped"
                result["reason"] = f"image_not_found: {ann['filename']}"
                return result

            try:
                with Image.open(img_path) as im:
                    img_w, img_h = im.size
            except Exception as e:
                result["status"] = "error"
                result["reason"] = f"image_read_error: {e}"
                return result

            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜
            x, y, w, h = ann["bbox"]
            
            # YOLO í¬ë§·: ì¤‘ì‹¬ì  ê¸°ì¤€ ì •ê·œí™”
            x_center = (x + w / 2) / img_w
            y_center = (y + h / 2) / img_h
            w_norm = w / img_w
            h_norm = h / img_h
            
            # ì¢Œí‘œ ë²”ìœ„ ê²€ì¦ (0~1)
            if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 0 <= w_norm <= 1 and 0 <= h_norm <= 1):
                result["status"] = "error"
                result["reason"] = f"invalid_bbox: ({x_center:.2f}, {y_center:.2f}, {w_norm:.2f}, {h_norm:.2f})"
                return result

            yolo_lines.append(f"{cls_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}")

        # YOLO ë¼ë²¨ íŒŒì¼ ì €ì¥
        if yolo_lines:
            txt_name = file.replace(".json", ".txt")
            txt_path = os.path.join(out_dir, txt_name)
            with open(txt_path, "w", encoding="utf-8") as f:
                f.write("\n".join(yolo_lines))
            
            result["lines"] = len(yolo_lines)
        else:
            result["status"] = "skipped"
            result["reason"] = "no_valid_boxes"
    
    except Exception as e:
        result["status"] = "error"
        result["reason"] = str(e)
    
    return result


def convert_json_to_yolo(json_dir, img_dir, out_dir, workers=4, verbose=True):
    """JSON ë¼ë²¨ â†’ YOLO txt ë³€í™˜ (ë³‘ë ¬ì²˜ë¦¬ + í†µê³„)"""
    os.makedirs(out_dir, exist_ok=True)
    
    json_files = [f for f in os.listdir(json_dir) if f.endswith(".json")]
    
    if not json_files:
        print(f"âŒ {json_dir}ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {"converted": 0, "skipped": 0, "errors": 0}
    
    print(f"\nğŸ”„ [1ë‹¨ê³„] JSON â†’ YOLO ë³€í™˜ ì‹œì‘: {len(json_files)}ê°œ íŒŒì¼")
    
    stats = {
        "converted": 0,
        "skipped": 0,
        "errors": 0,
        "total_boxes": 0,
        "error_details": []
    }
    
    args_list = [(f, json_dir, img_dir, out_dir) for f in json_files]
    
    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {executor.submit(convert_single_file, args): args[0] for args in args_list}
        
        with tqdm(total=len(json_files), desc="   ë³€í™˜ ì¤‘", unit="file") as pbar:
            for future in as_completed(futures):
                result = future.result()
                
                if result["status"] == "success":
                    stats["converted"] += 1
                    stats["total_boxes"] += result["lines"]
                elif result["status"] == "skipped":
                    stats["skipped"] += 1
                    if verbose:
                        stats["error_details"].append(f"âš ï¸ {result['file']}: {result['reason']}")
                else:
                    stats["errors"] += 1
                    stats["error_details"].append(f"âŒ {result['file']}: {result['reason']}")
                
                pbar.update(1)
    
    print(f"   âœ… ì„±ê³µ: {stats['converted']}ê°œ ({stats['total_boxes']}ê°œ ë°•ìŠ¤)")
    print(f"   âš ï¸ ìŠ¤í‚µ: {stats['skipped']}ê°œ")
    print(f"   âŒ ì˜¤ë¥˜: {stats['errors']}ê°œ")
    
    return stats


# ==================== ë°ì´í„°ì…‹ í•„í„°ë§ ====================
def filter_dataset(img_dir, lbl_dir, out_img, out_lbl, split_name=""):
    """ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­ ê²€ì¦ í›„ í•„í„°ë§"""
    os.makedirs(out_img, exist_ok=True)
    os.makedirs(out_lbl, exist_ok=True)
    
    label_files = [f for f in os.listdir(lbl_dir) if f.endswith(".txt")]
    
    copied = 0
    skipped = 0
    
    for lbl in tqdm(label_files, desc=f"   {split_name} í•„í„°ë§", unit="file"):
        base = os.path.splitext(lbl)[0]
        
        # ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í™•ì¥ì ì§€ì›
        img_file = None
        for ext in [".jpg", ".jpeg", ".png", ".JPG"]:
            candidate = os.path.join(img_dir, base + ext)
            if os.path.exists(candidate):
                img_file = candidate
                break
        
        lbl_file = os.path.join(lbl_dir, lbl)
        
        if img_file and os.path.exists(lbl_file):
            # ë¼ë²¨ íŒŒì¼ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            if os.path.getsize(lbl_file) > 0:
                shutil.copy(img_file, out_img)
                shutil.copy(lbl_file, out_lbl)
                copied += 1
            else:
                skipped += 1
        else:
            skipped += 1
    
    return copied, skipped


# ==================== YAML ìƒì„± ====================
def create_data_yaml(base_dir, output_path, train_path, val_path, test_path=None):
    """YOLO í•™ìŠµìš© data.yaml ìƒì„±"""
    data_yaml = {
        "path": base_dir.replace("\\", "/"),
        "train": train_path.replace("\\", "/"),
        "val": val_path.replace("\\", "/"),
        "nc": 5,
        "names": ["ì–´ì„ ", "ìƒì„ ", "êµ°í•¨", "ì‚¬ëŒ", "ìœ ì¡°ë¥˜"]
    }
    
    if test_path:
        data_yaml["test"] = test_path.replace("\\", "/")
    
    with open(output_path, "w", encoding="utf-8") as f:
        yaml.dump(data_yaml, f, allow_unicode=True, default_flow_style=False)
    
    print(f"   âœ… data.yaml ìƒì„±: {output_path}")


# ==================== ë©”ì¸ íŒŒì´í”„ë¼ì¸ ====================
def preprocess_army_dataset(base_dir, workers=8, skip_conversion=False):
    """
    ì „ì²´ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    Args:
        base_dir: ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
        skip_conversion: JSON ë³€í™˜ ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ë³€í™˜ëœ ê²½ìš°)
    """
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘   êµ­ë°© AI ë°ì´í„° ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ      â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # ê²½ë¡œ ì„¤ì •
    base_path = Path(base_dir)
    
    # ì›ë³¸ ê²½ë¡œ
    train_json_dir = base_path / "Train" / "json"
    train_img_dir = base_path / "Train" / "Origin"
    train_lbl_dir = base_path / "Train" / "labels"
    
    val_json_dir = base_path / "Val" / "json"
    val_img_dir = base_path / "Val" / "Origin"
    val_lbl_dir = base_path / "Val" / "labels"
    
    # í•„í„°ë§ëœ ë°ì´í„° ê²½ë¡œ
    filtered_base = base_path / "Filtered"
    train_out_img = filtered_base / "Train" / "images"
    train_out_lbl = filtered_base / "Train" / "labels"
    val_out_img = filtered_base / "Val" / "images"
    val_out_lbl = filtered_base / "Val" / "labels"
    
    # ========== 1ë‹¨ê³„: JSON â†’ YOLO ë³€í™˜ ==========
    if not skip_conversion:
        # Train ë³€í™˜
        if train_json_dir.exists():
            train_stats = convert_json_to_yolo(
                str(train_json_dir),
                str(train_img_dir),
                str(train_lbl_dir),
                workers=workers
            )
        
        # Val ë³€í™˜
        if val_json_dir.exists():
            val_stats = convert_json_to_yolo(
                str(val_json_dir),
                str(val_img_dir),
                str(val_lbl_dir),
                workers=workers
            )
    else:
        print("\nâ­ï¸  [1ë‹¨ê³„] JSON ë³€í™˜ ê±´ë„ˆë›°ê¸° (skip_conversion=True)")
    
    # ========== 2ë‹¨ê³„: ë°ì´í„°ì…‹ í•„í„°ë§ ==========
    print("\nğŸ” [2ë‹¨ê³„] ë°ì´í„°ì…‹ í•„í„°ë§ ì‹œì‘")
    
    train_copied, train_skipped = filter_dataset(
        str(train_img_dir),
        str(train_lbl_dir),
        str(train_out_img),
        str(train_out_lbl),
        split_name="Train"
    )
    
    val_copied, val_skipped = filter_dataset(
        str(val_img_dir),
        str(val_lbl_dir),
        str(val_out_img),
        str(val_out_lbl),
        split_name="Val"
    )
    
    print(f"   âœ… Train: {train_copied}ê°œ ë³µì‚¬, {train_skipped}ê°œ ìŠ¤í‚µ")
    print(f"   âœ… Val: {val_copied}ê°œ ë³µì‚¬, {val_skipped}ê°œ ìŠ¤í‚µ")
    
    # ========== 3ë‹¨ê³„: data.yaml ìƒì„± ==========
    print("\nğŸ“ [3ë‹¨ê³„] YOLO í•™ìŠµ ì„¤ì • íŒŒì¼ ìƒì„±")
    
    yaml_path = base_path / "data_filtered.yaml"
    create_data_yaml(
        base_dir=str(filtered_base),
        output_path=str(yaml_path),
        train_path="Train/images",
        val_path="Val/images"
    )
    
    # ========== ìµœì¢… ë¦¬í¬íŠ¸ ==========
    print("\n" + "="*50)
    print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print("="*50)
    print(f"ğŸ“Š ìµœì¢… ë°ì´í„°ì…‹:")
    print(f"   - Train: {train_copied}ê°œ")
    print(f"   - Val: {val_copied}ê°œ")
    print(f"   - ì´í•©: {train_copied + val_copied}ê°œ")
    print(f"\nğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: {filtered_base}")
    print(f"ğŸ“„ í•™ìŠµ ì„¤ì •: {yaml_path}")
    print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„: YOLO ëª¨ë¸ í•™ìŠµ")
    print(f"   python train.py --data {yaml_path} --epochs 100")


# ==================== ì‹¤í–‰ ì˜ˆì‹œ ====================
if __name__ == "__main__":
    # ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •
    BASE_DIR = r"C:/Army_project/data"
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    preprocess_army_dataset(
        base_dir=BASE_DIR,
        workers=8,              # CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •
        skip_conversion=False   # JSON ë³€í™˜ ê±´ë„ˆë›°ê¸° (False = ë³€í™˜ ìˆ˜í–‰)
    )